{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HOSSo94g4fb"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we0mwwMWg8No"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exCXsPrEg-pW"
      },
      "source": [
        "## Create folder and clone Git repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "repo_url = \"https://github.com/lukeblevins/PoliGraph-Setup.git\"\n",
        "folder_path = \"./Poligraph_Tool\"\n",
        "\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    os.makedirs(folder_path + \"/PoliGraph-Setup\")\n",
        "\n",
        "\n",
        "def clone_repository(repo_url, clone_path):\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"git\", \"clone\", repo_url, clone_path],\n",
        "            check=True,\n",
        "            stdout=subprocess.PIPE,\n",
        "            stderr=subprocess.PIPE,\n",
        "            text=True,\n",
        "        )\n",
        "        print(\"Repository cloned successfully:\")\n",
        "        print(result.stdout)\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(\"Error cloning repository:\")\n",
        "        print(e.stderr)\n",
        "\n",
        "\n",
        "clone_repository(repo_url, folder_path + \"/PoliGraph-Setup\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db_HXfvGiLUU"
      },
      "source": [
        "## Install dependencies for repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D1enqdCliN7B",
        "outputId": "e516c6c0-733e-49bf-8f5f-e043355c0eed"
      },
      "outputs": [],
      "source": [
        "cache_dir = \"./Poligraph_Tool/cache\"\n",
        "requirements_file = \"./Poligraph_Tool/PoliGraph-Setup/requirements.txt\"\n",
        "\n",
        "if not os.path.exists(cache_dir):\n",
        "    os.makedirs(cache_dir)\n",
        "\n",
        "subprocess.run(\n",
        "    [\"pip\", \"install\", \"--cache-dir\", cache_dir, \"-r\", requirements_file], check=True\n",
        ")\n",
        "subprocess.run(\n",
        "    [\n",
        "        \"pip\",\n",
        "        \"install\",\n",
        "        \"gdown\",\n",
        "        \"pyyaml\",\n",
        "        \"networkx\",\n",
        "        \"pandas\",\n",
        "        \"install-playwright\",\n",
        "        \"matplotlib\",\n",
        "        \"--cache-dir\",\n",
        "        cache_dir,\n",
        "    ],\n",
        "    check=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import installed libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gdown\n",
        "import yaml\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chX1e5AVqJsJ"
      },
      "source": [
        "## Download the model file from researchers' Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYGUdMQLo-Vg",
        "outputId": "e32523af-f361-4c79-fcb2-7886213469d0"
      },
      "outputs": [],
      "source": [
        "url = \"https://drive.google.com/uc?id=1qHifRx93EfTkg2x1e2W_lgQAgk7HcXhP\"\n",
        "output = \"./Poligraph_Tool/cache/poligrapher-extra-data.tar.gz\"\n",
        "\n",
        "if os.path.exists(output):\n",
        "    print(f\"Using cached file: {output}\")\n",
        "else:\n",
        "    print(f\"Downloading file from {url}\")\n",
        "    gdown.download(url, output, quiet=False)\n",
        "    print(f\"File downloaded to: {output}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hesotvb5iZDI"
      },
      "source": [
        "## Download spaCy model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3ZYhYUsifcY",
        "outputId": "d946e148-a710-4a21-88d0-e76df9ce3b89"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# Download spaCy model\n",
        "print(f\"Downloading spaCy model...\")\n",
        "spacy.cli.download(\"en_core_web_trf\")\n",
        "print(f\"SpaCy model downloaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbUSm4X-qYgY"
      },
      "source": [
        "## Unzip and move model file to correct folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrgUnmBkp8oS"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "# Change the current working directory\n",
        "os.chdir(\"./Poligraph_Tool/\")\n",
        "\n",
        "# Extract the tar.gz file\n",
        "with tarfile.open(\"./cache/poligrapher-extra-data.tar.gz\", \"r:gz\") as tar:\n",
        "    os.chdir(\"./PoliGraph-Setup/\")\n",
        "    tar.extractall(path=\"./poligrapher/extra-data\")\n",
        "\n",
        "# Remove the tar.gz file\n",
        "# os.remove(\"../cache/poligrapher-extra-data.tar.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIx7N8FPq_xT"
      },
      "source": [
        "## Install tool as python package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUEArelrqsqr",
        "outputId": "428c2aa0-1794-4c4a-f8b9-daea6ea47a09"
      },
      "outputs": [],
      "source": [
        "subprocess.run(\n",
        "    [\"pip\", \"install\", \"--cache-dir\", \"../cache/\", \"--editable\", \".\"], check=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beIdrvA1r1V4"
      },
      "source": [
        "## Install browsers so that playwright can scrape web pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BttUs_LCrxPQ",
        "outputId": "3d5293d8-3904-4d2c-f771-4935d7e58c43"
      },
      "outputs": [],
      "source": [
        "from install_playwright import install\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "\n",
        "async def main():\n",
        "    async with async_playwright() as p:\n",
        "        install(p.chromium)\n",
        "\n",
        "\n",
        "# Run the async function\n",
        "await main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vynj9x7UrF5z"
      },
      "source": [
        "# Convert privacy policy to knowledge graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get policy documents from `policy_list.json` file and generate their knowledge graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpRdmcP3VyDG",
        "outputId": "8b79bd6c-8616-4a82-dcd0-75e532ed101b"
      },
      "outputs": [],
      "source": [
        "# Open the policy urls file\n",
        "with open(\"../../policy_list.json\", \"r\") as file:\n",
        "    policy_urls = json.load(file)[\"policy_urls\"]\n",
        "\n",
        "output_folder_prefix = \"../../output/\"\n",
        "\n",
        "for policy in policy_urls:\n",
        "    policy_name = policy[\"name\"]\n",
        "    policy_url = policy[\"path\"]\n",
        "    policy_kind = policy[\"kind\"]\n",
        "\n",
        "    # get domain name from url for folder name\n",
        "    output_folder = output_folder_prefix + policy_name.replace(\" \", \"_\")\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    print(f\"Generating graph for {policy_name} from {policy_url}\")\n",
        "    try:\n",
        "        if policy_kind == \"pdf\":\n",
        "            # Run the pdf parser\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    \"python\",\n",
        "                    \"-m\",\n",
        "                    \"poligrapher.scripts.pdf_parser\",\n",
        "                    policy_url,\n",
        "                    output_folder,\n",
        "                ],\n",
        "                check=True,\n",
        "            )\n",
        "            html_path = os.path.join(output_folder, \"output.html\")\n",
        "            # Run the html crawler\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    \"python\",\n",
        "                    \"-m\",\n",
        "                    \"poligrapher.scripts.html_crawler\",\n",
        "                    html_path,\n",
        "                    output_folder,\n",
        "                ],\n",
        "                check=False,\n",
        "            )\n",
        "        else:\n",
        "            # Run the html crawler\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    \"python\",\n",
        "                    \"-m\",\n",
        "                    \"poligrapher.scripts.html_crawler\",\n",
        "                    policy_url,\n",
        "                    output_folder,\n",
        "                ],\n",
        "                check=False,\n",
        "            )\n",
        "            # Run the html crawler\n",
        "            subprocess.run(\n",
        "                [\n",
        "                    \"python\",\n",
        "                    \"-m\",\n",
        "                    \"poligrapher.scripts.html_crawler\",\n",
        "                    policy_url,\n",
        "                    output_folder,\n",
        "                ],\n",
        "                check=True,\n",
        "            )\n",
        "\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"python\",\n",
        "                \"-m\",\n",
        "                \"poligrapher.scripts.init_document\",\n",
        "                output_folder,\n",
        "            ],\n",
        "            check=False,\n",
        "        )\n",
        "        # Run the annotators\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"python\",\n",
        "                \"-m\",\n",
        "                \"poligrapher.scripts.run_annotators\",\n",
        "                output_folder,\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        # Command to create the graph generates a .yaml file with all the data\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"python\",\n",
        "                \"-m\",\n",
        "                \"poligrapher.scripts.build_graph\",\n",
        "                output_folder,\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        # Command to create the graph generates a .graphml file.\n",
        "        subprocess.run(\n",
        "            [\n",
        "                \"python\",\n",
        "                \"-m\",\n",
        "                \"poligrapher.scripts.build_graph\",\n",
        "                \"--pretty\",\n",
        "                output_folder,\n",
        "            ],\n",
        "            check=True,\n",
        "        )\n",
        "        print(f\"Graphs for {policy_url} have been generated\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Error generating graphs for {policy_url}\")\n",
        "        print(e.stderr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# View output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4iTfNJTy9NT"
      },
      "source": [
        "If you just ran the basic command to generate a graph then `graph-original.full.yml` and `graph-orginal.yml` are the final ouptut. \n",
        "\n",
        "For the pretty graph the output is a `graph-orginal.graphml` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcrACaVTwrmh",
        "outputId": "55051b6c-a38c-4558-bd4f-86c572b2f54a"
      },
      "outputs": [],
      "source": [
        "# Change the current working directory\n",
        "os.chdir(\"../../output/\")\n",
        "subprocess.run([\"ls\", \"-R\"], check=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLrTZRdxEA_g"
      },
      "source": [
        "## Visualize the `graph-original.full.yml` file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQy7PG3FyauN"
      },
      "source": [
        "### Knowledge Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "8gpCknq8ydbX",
        "outputId": "bb811f6a-15f9-49c0-9d42-5c380d1ac645"
      },
      "outputs": [],
      "source": [
        "def needs_graphml_visual(folder):\n",
        "    pattern = os.path.join(folder, \"*\" + \".yml\")\n",
        "    has_graphml = len(glob.glob(pattern)) > 0\n",
        "    if has_graphml:\n",
        "        return not os.path.exists(f\"{folder}/knowledge_graph.png\")\n",
        "    return False\n",
        "\n",
        "\n",
        "# loop through the output folder and get the graph files\n",
        "graph_files = []\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for dir in dirs:\n",
        "        full_dir_path = os.path.join(root, dir)\n",
        "        if needs_graphml_visual(full_dir_path):\n",
        "            yml_file = os.path.join(full_dir_path, \"graph-original.full.yml\")\n",
        "            if os.path.exists(yml_file):\n",
        "                graph_files.append(yml_file)\n",
        "\n",
        "for graph_file in graph_files:\n",
        "    parent_folder = os.path.dirname(graph_file)\n",
        "    output_png = os.path.join(parent_folder, \"knowledge_graph.png\")\n",
        "    print(f\"Converting {graph_file} to PNG\")\n",
        "\n",
        "    with open(graph_file, \"r\") as file:\n",
        "        data = yaml.safe_load(file)\n",
        "\n",
        "    G = nx.DiGraph()\n",
        "    # nodes\n",
        "    for node in data.get(\"nodes\", []):\n",
        "        G.add_node(node[\"id\"], type=node[\"type\"])\n",
        "    # edges\n",
        "    for link in data.get(\"links\", []):\n",
        "        G.add_edge(link[\"source\"], link[\"target\"], label=link[\"key\"])\n",
        "\n",
        "    plt.figure(figsize=(20, 15), facecolor=\"white\")\n",
        "    pos = nx.spring_layout(G, k=0.5)\n",
        "    nx.draw(\n",
        "        G,\n",
        "        pos,\n",
        "        with_labels=True,\n",
        "        node_size=3000,\n",
        "        node_color=\"lightblue\",\n",
        "        edge_color=\"gray\",\n",
        "    )\n",
        "    edge_labels = nx.get_edge_attributes(G, \"label\")\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "    plt.title(\"Knowledge Graph - \" + parent_folder)\n",
        "    plt.savefig(output_png, facecolor=\"white\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPp5Ljejye9o"
      },
      "source": [
        "### Table of Relations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCcISE-Zyi8K",
        "outputId": "bec2e1c0-ec84-4505-8016-f797c7e0fb4b"
      },
      "outputs": [],
      "source": [
        "def needs_csv_extract(folder):\n",
        "    pattern = os.path.join(folder, \"*\" + \".yml\")\n",
        "    has_graphml = len(glob.glob(pattern)) > 0\n",
        "    if has_graphml:\n",
        "        return not os.path.exists(f\"{folder}/complete_extracted_data.csv\")\n",
        "    return False\n",
        "\n",
        "\n",
        "# load yml file\n",
        "def load_yml(file_path):\n",
        "    if os.path.exists(file_path):\n",
        "        try:\n",
        "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "                return yaml.safe_load(file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading YAML: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# get relationships from yml file\n",
        "def extract_yml_relationships(yaml_data):\n",
        "    relationships = []\n",
        "    if yml_data and \"links\" in yml_data:\n",
        "        for link in yml_data[\"links\"]:\n",
        "            source = link.get(\"source\", \"Unknown Source\")\n",
        "            target = link.get(\"target\", \"Unknown Target\")\n",
        "            relation = link.get(\"key\", \"Unknown Relationship\")\n",
        "            # combine policy excerpts(references)\n",
        "            text = \" | \".join(link.get(\"text\", []))\n",
        "            purposes = (\n",
        "                \" | \".join(\n",
        "                    [\n",
        "                        f\"{k}: {', '.join(v)}\"\n",
        "                        for k, v in link.get(\"purposes\", {}).items()\n",
        "                    ]\n",
        "                )\n",
        "                if link.get(\"purposes\")\n",
        "                else \"None\"\n",
        "            )\n",
        "            relationships.append((source, relation, target, text, purposes))\n",
        "    return relationships\n",
        "\n",
        "\n",
        "# get file paths\n",
        "yml_path = \"graph-original.full.yml\"\n",
        "\n",
        "# loop through the output folder and get the graph files\n",
        "graph_files = []\n",
        "for root, dirs, files in os.walk(\".\"):\n",
        "    for dir in dirs:\n",
        "        full_dir_path = os.path.join(root, dir)\n",
        "        if needs_csv_extract(full_dir_path):\n",
        "            yml_file = os.path.join(full_dir_path, yml_path)\n",
        "            if os.path.exists(yml_file):\n",
        "                graph_files.append(yml_file)\n",
        "\n",
        "for graph_file in graph_files:\n",
        "    print(f\"\\nExtracting relationships from '{graph_file}'\")\n",
        "    parent_folder = os.path.dirname(graph_file)\n",
        "    output_csv_path = os.path.join(parent_folder, \"complete_extracted_data.csv\")\n",
        "    # call the funtions\n",
        "    yml_data = load_yml(graph_file)\n",
        "\n",
        "    # get relationships from both files\n",
        "    yml_relationships = extract_yml_relationships(yml_data) if yml_data else []\n",
        "\n",
        "    # combine results to a DF\n",
        "    df_combined = pd.DataFrame(\n",
        "        yml_relationships,\n",
        "        columns=[\"Entity\", \"Relation\", \"Target Entity\", \"Policy Text\", \"Purposes\"],\n",
        "    )\n",
        "\n",
        "    # save the csv\n",
        "    df_combined.to_csv(output_csv_path, index=False)\n",
        "    print(f\"\\nSaved extracted data to '{output_csv_path}'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
